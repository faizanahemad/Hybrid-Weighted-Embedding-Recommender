{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T19:18:42.732101Z",
     "start_time": "2019-11-17T19:18:38.801356Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import display, HTML\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T19:18:46.147130Z",
     "start_time": "2019-11-17T19:18:42.734167Z"
    }
   },
   "outputs": [],
   "source": [
    "from hwer.utils import normalize_affinity_scores_by_user_item, normalize_affinity_scores_by_user\n",
    "\n",
    "from hwer.utils import unit_length, build_user_item_dict, build_item_user_dict, cos_sim, shuffle_copy\n",
    "from hwer import HybridRecommender\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Dict, Tuple, Sequence, Type, Set, Optional\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from surprise.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm,tqdm_notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T11:17:13.706779Z",
     "start_time": "2019-11-17T11:17:04.556428Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "users = pd.read_csv(\"users.csv\", sep=\"\\t\", engine=\"python\")\n",
    "movies = pd.read_csv(\"movies.csv\", sep=\"\\t\", engine=\"python\")\n",
    "ratings = pd.read_csv(\"ratings.csv\", sep=\"\\t\", engine=\"python\")\n",
    "\n",
    "users['user_id'] = users['user_id'].astype(str)\n",
    "movies['movie_id'] = movies['movie_id'].astype(str)\n",
    "ratings['movie_id'] = ratings['movie_id'].astype(str)\n",
    "ratings['user_id'] = ratings['user_id'].astype(str)\n",
    "\n",
    "print(users.shape, movies.shape, ratings.shape)\n",
    "\n",
    "\n",
    "from importlib import reload\n",
    "import hwer\n",
    "reload(hwer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T11:17:14.283812Z",
     "start_time": "2019-11-17T11:17:13.710120Z"
    }
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "movies.genres = movies.genres.fillna(\"[]\").apply(literal_eval)\n",
    "movies['year'] = movies['year'].fillna(-1).astype(int)\n",
    "\n",
    "movies.keywords = movies.keywords.fillna(\"[]\").apply(literal_eval)\n",
    "movies.keywords = movies.keywords.apply(lambda x: \" \".join(x))\n",
    "\n",
    "movies.tagline = movies.tagline.fillna(\"\")\n",
    "text_columns = [\"title\",\"keywords\",\"overview\",\"tagline\",\"original_title\"]\n",
    "movies[text_columns] = movies[text_columns].fillna(\"\")\n",
    "\n",
    "movies['text'] = movies[\"title\"] +\" \"+ movies[\"keywords\"] +\" \"+ movies[\"overview\"] +\" \"+ movies[\"tagline\"] +\" \"+ movies[\"original_title\"]\n",
    "movies[\"title_length\"] = movies[\"title\"].apply(len)\n",
    "movies[\"overview_length\"] = movies[\"overview\"].apply(len)\n",
    "movies[\"runtime\"] = movies[\"runtime\"].fillna(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T11:17:18.255305Z",
     "start_time": "2019-11-17T11:17:14.286412Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings.head().values\n",
    "user_item_affinities = [[row[0], row[1], row[2]] for row in ratings.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T11:31:23.020669Z",
     "start_time": "2019-11-17T11:29:24.836084Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from hwer import MultiCategoricalEmbedding, FlairGlove100AndBytePairEmbedding, CategoricalEmbedding, NumericEmbedding, FlairGlove100Embedding\n",
    "from hwer import Feature, FeatureSet, ContentRecommendation, FeatureType\n",
    "\n",
    "embedding_mapper = {}\n",
    "embedding_mapper['gender'] = CategoricalEmbedding(n_dims=1)\n",
    "embedding_mapper['age'] = CategoricalEmbedding(n_dims=1)\n",
    "embedding_mapper['occupation'] = CategoricalEmbedding(n_dims=2)\n",
    "embedding_mapper['zip'] = CategoricalEmbedding(n_dims=2)\n",
    "\n",
    "embedding_mapper['text'] = FlairGlove100Embedding()\n",
    "embedding_mapper['numeric'] = NumericEmbedding(2)\n",
    "embedding_mapper['genres'] = MultiCategoricalEmbedding(n_dims=2)\n",
    "\n",
    "\n",
    "recsys = ContentRecommendation(embedding_mapper=embedding_mapper, knn_params=None, n_output_dims=8, rating_scale=(1,5))\n",
    "\n",
    "\n",
    "u1 = Feature(feature_name=\"gender\", feature_type=FeatureType.CATEGORICAL, values=users.gender.values)\n",
    "u2 = Feature(feature_name=\"age\", feature_type=FeatureType.CATEGORICAL, values=users.age.astype(str).values)\n",
    "u3 = Feature(feature_name=\"occupation\", feature_type=FeatureType.CATEGORICAL, values=users.occupation.astype(str).values)\n",
    "u4 = Feature(feature_name=\"zip\", feature_type=FeatureType.CATEGORICAL, values=users.zip.astype(str).values)\n",
    "user_data = FeatureSet([u1, u2, u3, u4])\n",
    "\n",
    "i1 = Feature(feature_name=\"text\", feature_type=FeatureType.STR, values=movies.text.values)\n",
    "i2 = Feature(feature_name=\"genres\", feature_type=FeatureType.MULTI_CATEGORICAL, values=movies.genres.values)\n",
    "i3 = Feature(feature_name=\"numeric\", feature_type=FeatureType.NUMERIC, values=movies[[\"title_length\", \"overview_length\", \"runtime\"]].values)\n",
    "item_data = FeatureSet([i1, i2, i3])\n",
    "\n",
    "kwargs = {}\n",
    "kwargs['user_data'] = user_data\n",
    "kwargs['item_data'] = item_data\n",
    "\n",
    "user_vectors, item_vectors = recsys.fit(users.user_id.values, movies.movie_id.values,\n",
    "               user_item_affinities, **kwargs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T11:33:10.862180Z",
     "start_time": "2019-11-17T11:33:10.790275Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res, dist = zip(*recsys.find_items_for_user(user='1', positive=[], negative=[]))\n",
    "res = res[:100]\n",
    "\n",
    "preds = set(movies[movies.movie_id.isin(res)][\"title\"])\n",
    "actuals = set(movies.merge(ratings[ratings.user_id=='1'],on='movie_id')[\"title\"])\n",
    "\n",
    "len(preds.intersection(actuals))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T13:24:49.183330Z",
     "start_time": "2019-11-15T13:24:49.173382Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow.keras.backend as K\n",
    "class FixedNorm(tf.keras.constraints.Constraint):\n",
    "    \"\"\"\n",
    "    Refer: \n",
    "    https://github.com/keras-team/keras/issues/1580\n",
    "    https://github.com/tensorflow/tensorflow/issues/33755\n",
    "    \"\"\"\n",
    "    def __init__(self, m=1.):\n",
    "        self.m = m\n",
    "\n",
    "    def __call__(self, p):\n",
    "        p = K.transpose(p)\n",
    "        unit_norm = p / (K.sqrt(K.sum(K.square(p), axis=0)) + 1e-6)\n",
    "        unit_norm = K.transpose(unit_norm)\n",
    "        return unit_norm * self.m\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'name': self.__class__.__name__, 'm': self.m}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T17:46:32.432164Z",
     "start_time": "2019-11-15T17:46:32.313642Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "actual_vs_pred = [(r,cos_sim(item_vectors[self.item_id_to_index[i]],item_vectors[self.item_id_to_index[j]])) for i,j,r in random_item_item_aff]\n",
    "np.sqrt(np.mean(np.square(np.array([a-p for a,p in actual_vs_pred]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T17:02:16.872819Z",
     "start_time": "2019-11-28T17:02:15.475718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 22.5257\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 21.7772\n",
      "[array([0.2991138 , 0.51968646], dtype=float32), array([0.36083567, 0.08598872], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2991138, 0.51968646, 0.36083567, 0.085988715]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "batch_size = 2\n",
    "\n",
    "\n",
    "def generate_training_samples():\n",
    "    def generator():\n",
    "        for i in range(batch_size*10):\n",
    "            yield (np.random.rand(3),np.random.rand(3), np.random.rand()), 5\n",
    "    return generator\n",
    "\n",
    "output_shapes = (((3), (3), ()), ())\n",
    "output_types = (((tf.float32), (tf.float32), tf.float32), tf.float32)\n",
    "train = tf.data.Dataset.from_generator(generate_training_samples(),\n",
    "                                       output_types=output_types, output_shapes=output_shapes,)\n",
    "\n",
    "train = train.shuffle(batch_size).batch(batch_size)\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "input_1 = keras.Input(shape=(3,))\n",
    "input_2 = keras.Input(shape=(3,))\n",
    "input_3 = keras.Input(shape=(1,))\n",
    "\n",
    "inputs = K.concatenate([input_1, input_2, input_3])\n",
    "inputs = tf.keras.layers.Flatten()(inputs)\n",
    "dense_1 = layers.Dense(16, activation='relu')\n",
    "\n",
    "\n",
    "x = dense_1(inputs)\n",
    "\n",
    "x = layers.Dense(8, activation=\"relu\")(x)\n",
    "\n",
    "pred = layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "model = keras.Model(inputs=[input_1, input_2, input_3],\n",
    "                    outputs=[pred])\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.1, amsgrad=False)\n",
    "model.compile(optimizer=adam,\n",
    "              loss=['mean_squared_error'])\n",
    "\n",
    "\n",
    "model.fit(train, epochs=2)\n",
    "\n",
    "\n",
    "def generate_prediction_samples():\n",
    "    def generator():\n",
    "        for i in range(batch_size*2):\n",
    "            yield np.random.rand(3),np.random.rand(3), np.random.rand()\n",
    "    return generator\n",
    "\n",
    "output_shapes = (3, 3, ())\n",
    "output_types = (tf.float32, tf.float32, tf.float32)\n",
    "predict = tf.data.Dataset.from_generator(generate_prediction_samples(),\n",
    "                                       output_types=output_types, output_shapes=output_shapes,)\n",
    "\n",
    "predict = predict.batch(batch_size)\n",
    "next(iter(predict))\n",
    "\n",
    "model.predict(next(iter(predict)))\n",
    "model.predict(x=tf.compat.v1.data.make_one_shot_iterator(predict).get_next())\n",
    "model.predict(x=predict.make_one_shot_iterator().get_next()).reshape((-1))\n",
    "\n",
    "preds = []\n",
    "for x in predict:\n",
    "    preds.append(model.predict(x).reshape((-1)))\n",
    "    \n",
    "from more_itertools import flatten\n",
    "print(preds)\n",
    "list(flatten(preds))\n",
    "\n",
    "# model.predict_generator(iter(predict), steps=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T19:56:09.897178Z",
     "start_time": "2019-11-17T19:56:09.821635Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_prediction_samples():\n",
    "    def generator():\n",
    "        for i in range(batch_size*2):\n",
    "#             yield np.random.rand(3),np.random.rand(3)\n",
    "            yield [np.random.rand(3).reshape((-1,3)),np.random.rand(3).reshape((-1,3)), np.array([np.random.rand()])]\n",
    "\n",
    "\n",
    "    return generator\n",
    "\n",
    "\n",
    "model.predict_generator(iter(generate_prediction_samples()()), steps=4)\n",
    "model.predict_generator(generate_prediction_samples()(), steps=4)\n",
    "\n",
    "\n",
    "# model.predict(next(iter(generate_prediction_samples()())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hybrid-recsys] *",
   "language": "python",
   "name": "conda-env-hybrid-recsys-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
